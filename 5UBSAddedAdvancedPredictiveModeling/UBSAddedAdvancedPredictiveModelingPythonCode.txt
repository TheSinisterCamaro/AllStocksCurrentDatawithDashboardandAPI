import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from datetime import timedelta

# Function to create a directory for saving the results
def create_directory(base_path, stock_name):
    directory_path = os.path.join(base_path, f"{stock_name}_results")
    if not os.path.exists(directory_path):
        os.makedirs(directory_path)
    return directory_path

# Function to collect and clean historical stock data
def collect_and_clean_data(ticker, start_date, end_date):
    # Download the data from Yahoo Finance
    data = yf.download(ticker, start=start_date, end=end_date)
    
    # Handle missing values by applying linear interpolation
    if data.isnull().values.any():
        print("Missing values detected. Applying linear interpolation...")
        data.interpolate(method='linear', inplace=True)
    
    return data

# Function to prepare data for LSTM with additional features
def prepare_lstm_data_with_features(data, look_back=90):
    # Adding more features (e.g., Moving Averages, RSI, Volatility)
    data['MA_20'] = data['Close'].rolling(window=20).mean()
    data['MA_50'] = data['Close'].rolling(window=50).mean()
    data['RSI'] = data['Close'].rolling(window=14).apply(
        lambda x: 100 - (100 / (1 + (x.diff().clip(lower=0).sum() / abs(x.diff().clip(upper=0).sum()))))
    )
    data['Volatility'] = data['Close'].rolling(window=20).std()

    # Drop rows with NaN values that were generated by rolling operations
    data.dropna(inplace=True)

    # Normalize the data to the range [0, 1]
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(data)

    # Prepare input sequences (X) and output values (y)
    X, y = [], []
    for i in range(look_back, len(scaled_data)):
        X.append(scaled_data[i-look_back:i])
        y.append(scaled_data[i, 0])  # We are predicting the closing price (first column)

    # Convert lists to numpy arrays
    X, y = np.array(X), np.array(y)
    
    return X, y, scaler

# Function to build and train the LSTM model
def train_lstm_model(X_train, y_train, output_dir, stock_name):
    # Define the LSTM model architecture
    model = Sequential()
    model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(Dropout(0.2))  # Adding dropout for regularization
    model.add(LSTM(units=100))
    model.add(Dropout(0.2))  # Adding another dropout layer
    model.add(Dense(1))  # Output layer

    # Compile the model with Adam optimizer and mean squared error loss
    model.compile(optimizer='adam', loss='mean_squared_error')
    
    # Train the model on the training data
    model.fit(X_train, y_train, epochs=50, batch_size=32)

    # Save the trained model to disk
    model_path = os.path.join(output_dir, f"{stock_name}_lstm_model.h5")
    model.save(model_path)
    print(f"LSTM model saved to {model_path}")

    return model

# Function to plot and save various graphs including historical prices, moving averages, RSI, and volatility
def plot_and_save_graphs(data, output_dir, stock_name):
    # Plot historical prices with moving averages
    plt.figure(figsize=(10, 6))
    plt.plot(data['Close'], label='Close Price')
    plt.plot(data['MA_20'], label='20-Day Moving Average')
    plt.plot(data['MA_50'], label='50-Day Moving Average')
    plt.title(f'{stock_name} Historical Prices with Moving Averages')
    plt.xlabel('Date')
    plt.ylabel('Price (USD)')
    plt.legend()
    plt.savefig(os.path.join(output_dir, f"{stock_name}_historical_prices_moving_averages.png"))
    plt.close()

    # Plot RSI (Relative Strength Index)
    plt.figure(figsize=(10, 6))
    plt.plot(data['RSI'], label='RSI')
    plt.axhline(30, linestyle='--', color='red')
    plt.axhline(70, linestyle='--', color='red')
    plt.title(f'{stock_name} Relative Strength Index (RSI)')
    plt.xlabel('Date')
    plt.ylabel('RSI')
    plt.legend()
    plt.savefig(os.path.join(output_dir, f"{stock_name}_RSI.png"))
    plt.close()

    # Plot volatility
    plt.figure(figsize=(10, 6))
    plt.plot(data['Volatility'], label='Volatility')
    plt.title(f'{stock_name} Volatility')
    plt.xlabel('Date')
    plt.ylabel('Volatility')
    plt.legend()
    plt.savefig(os.path.join(output_dir, f"{stock_name}_Volatility.png"))
    plt.close()

# Function to predict future stock prices using the trained LSTM model
def predict_future_prices_lstm(model, data, scaler, output_dir, stock_name, look_back=90, future_days=365):
    # Extract the last 'look_back' number of rows for all features
    last_data = data[-look_back:].values

    # Scale the last_data array using the scaler fitted on training data
    scaled_last_data = scaler.transform(last_data)

    # Prepare the input for prediction
    future_inputs = np.reshape(scaled_last_data, (1, look_back, scaled_last_data.shape[1]))
    predictions = []

    # Generate predictions for the specified number of future days
    for _ in range(future_days):
        pred = model.predict(future_inputs)
        predictions.append(pred[0, 0])  # Append only the closing price prediction

        # Shift the input sequence left by one and add the new prediction
        future_inputs = np.roll(future_inputs, -1, axis=1)
        future_inputs[0, -1, 0] = pred  # Set the last element to the new prediction

    # Since predictions only include the closing price, we need to inverse transform just this column
    closing_price_predictions = np.array(predictions).reshape(-1, 1)
    
    # Create a dummy array with the same shape as the original scaled data, but only update the closing price column
    dummy_scaled_data = np.zeros((closing_price_predictions.shape[0], scaler.n_features_in_))
    dummy_scaled_data[:, 0] = closing_price_predictions.flatten()

    # Apply inverse transform on the dummy array to get the actual closing prices
    inverse_transformed_predictions = scaler.inverse_transform(dummy_scaled_data)[:, 0]

    # Generate dates for the future predictions
    future_dates = [data.index[-1] + timedelta(days=i) for i in range(1, future_days + 1)]
    forecast_series = pd.Series(inverse_transformed_predictions.flatten(), index=future_dates)

    # Plot and save the future predictions
    plt.figure(figsize=(10, 6))
    plt.plot(data.index, data['Close'], label='Historical Close Price')
    plt.plot(forecast_series.index, forecast_series, label='Predicted Close Price', linestyle='--')
    plt.title(f'{stock_name} LSTM Predicted Closing Prices for the Next Year')
    plt.xlabel('Date')
    plt.ylabel('Price (USD)')
    plt.legend()
    plot_future_path = os.path.join(output_dir, f"{stock_name}_lstm_future_predictions.png")
    plt.savefig(plot_future_path)
    plt.close()

    # Save the predictions to a CSV file
    forecast_series.to_csv(os.path.join(output_dir, f"{stock_name}_lstm_future_predictions.csv"))
    print(f"Future predictions saved to {output_dir}")

# Parameters for the model
ticker = "UBS"
start_date = "2010-01-01"  # Using a longer historical period for training
end_date = "2023-01-01"
base_output_dir = r"C:\File\Path\Here" # Add your file path on where to store the output files.

# Automate the full process
output_dir = create_directory(base_output_dir, ticker)
ubs_data = collect_and_clean_data(ticker, start_date, end_date)

# Prepare data for LSTM with additional features
X_train, y_train, scaler = prepare_lstm_data_with_features(ubs_data)
lstm_model = train_lstm_model(X_train, y_train, output_dir, ticker)

# Plot historical data, moving averages, RSI, and volatility
plot_and_save_graphs(ubs_data, output_dir, ticker)

# Predict the next year's prices with LSTM
predict_future_prices_lstm(lstm_model, ubs_data, scaler, output_dir, ticker, future_days=365)
